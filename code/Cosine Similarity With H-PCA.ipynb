{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from math import log,sqrt\n",
    "import operator\n",
    "\n",
    "# Hack to shut up deprecation warning wrt something in the stemmer\n",
    "import sys, importlib\n",
    "sys.modules['sklearn.externals.six'] = importlib.import_module('six')\n",
    "\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from load_map import *\n",
    "from asgn2 import *\n",
    "\n",
    "from scipy.spatial.distance import cosine as weighted_cosine_dist\n",
    "\n",
    "file_positive = 'positive.txt'\n",
    "file_negative = 'negative.txt'\n",
    "\n",
    "positive_words = np.loadtxt(file_positive, dtype='U')\n",
    "negative_words = np.loadtxt(file_negative, dtype='U')\n",
    "positive_words = set([tw_stemmer(word) for word in positive_words]) #stemming might create duplicates; remove them\n",
    "negative_words = set([tw_stemmer(word) for word in negative_words])\n",
    "#find IDs of the words\n",
    "\n",
    "positive_word_ids = []\n",
    "for word in positive_words:\n",
    "    if word in word2wid.keys():\n",
    "        positive_word_ids.append(word2wid[word])\n",
    "    \n",
    "    \n",
    "negative_word_ids = []\n",
    "for word in negative_words:\n",
    "    if word in word2wid.keys():\n",
    "        negative_word_ids.append(word2wid[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the stemmer\n",
    "STEMMER = PorterStemmer()\n",
    "\n",
    "#Define the cosine similarity measure\n",
    "def cos_sim_hpca(v0,v1):\n",
    "  '''Compute the cosine similarity between two sparse vectors.\n",
    "\n",
    "  :type v0: dict\n",
    "  :type v1: dict\n",
    "  :param v0: first vector\n",
    "  :param v1: second vector\n",
    "  :rtype: float\n",
    "  :return: cosine between v0 and v1\n",
    "  '''\n",
    "  # We recommend that you store the sparse vectors as dictionaries\n",
    "  # with keys giving the indices of the non-zero entries, and values\n",
    "  # giving the values at those dimensions.\n",
    "\n",
    "  \n",
    "  return np.dot(v0,v1)/(np.sum(v0**2)*np.sum(v1**2))**(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_counts(filename, wids):\n",
    "    '''Reads the counts from file. It returns counts for all words, but to\n",
    "    save memory it only returns cooccurrence counts for the words\n",
    "    whose ids are listed in wids.\n",
    "\n",
    "    :type filename: string\n",
    "    :type wids: list\n",
    "    :param filename: where to read info from\n",
    "    :param wids: a list of word ids\n",
    "    :returns: occurence counts, cooccurence counts, and tot number of observations\n",
    "    '''\n",
    "    o_counts = {} # Occurence counts\n",
    "    co_counts = {} # Cooccurence counts\n",
    "    fp = open(filename)\n",
    "    N = float(next(fp))\n",
    "    for line in fp:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        wid0 = int(line[0])\n",
    "        o_counts[wid0] = int(line[1])\n",
    "        if(wid0 in wids):\n",
    "            co_counts[wid0] = dict([int(y) for y in x.split(\" \")] for x in line[2:])\n",
    "\n",
    "    return (o_counts, co_counts, N)\n",
    "\n",
    "def get_o_counts(filename):\n",
    "    '''Reads the counts from file. It returns counts for all words, but to\n",
    "    save memory it only returns cooccurrence counts for the words\n",
    "    whose ids are listed in wids.\n",
    "\n",
    "    :type filename: string\n",
    "    :type wids: list\n",
    "    :param filename: where to read info from\n",
    "    :param wids: a list of word ids\n",
    "    :returns: occurence counts, cooccurence counts, and tot number of observations\n",
    "    '''\n",
    "    o_counts = {} # Occurence counts\n",
    "    co_counts = {} # Cooccurence counts\n",
    "    fp = open(filename)\n",
    "    N = float(next(fp))\n",
    "    for line in fp:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        wid0 = int(line[0])\n",
    "        o_counts[wid0] = int(line[1])\n",
    "\n",
    "    return o_counts\n",
    "\n",
    "\n",
    "def print_sorted_pairs(similarities, o_counts, first=0, last=100):\n",
    "    '''Sorts the pairs of words by their similarity scores and prints\n",
    "    out the sorted list from index first to last, along with the\n",
    "    counts of each word in each pair.\n",
    "\n",
    "    :type similarities: dict \n",
    "    :type o_counts: dict\n",
    "    :type first: int\n",
    "    :type last: int\n",
    "    :param similarities: the word id pairs (keys) with similarity scores (values)\n",
    "    :param o_counts: the counts of each word id\n",
    "    :param first: index to start printing from\n",
    "    :param last: index to stop printing\n",
    "    :return: none\n",
    "    '''\n",
    "    if first < 0: last = len(similarities)\n",
    "    for pair in sorted(similarities.keys(), key=lambda x: similarities[x], reverse = True)[first:last]:\n",
    "        word_pair = (wid2word[pair[0]], wid2word[pair[1]])\n",
    "        print(\"{:.2f}\\t{:30}\\t{}\\t{}\".format(similarities[pair],str(word_pair),\n",
    "                                             o_counts[pair[0]],o_counts[pair[1]]))\n",
    "\n",
    "def freq_v_sim(sims):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for pair in sims.items():\n",
    "        ys.append(pair[1])\n",
    "        c0 = o_counts[pair[0][0]]\n",
    "        c1 = o_counts[pair[0][1]]\n",
    "        xs.append(min(c0,c1))\n",
    "    plt.clf() # clear previous plots (if any)\n",
    "    plt.xscale('log') #set x axis to log scale. Must do *before* creating plot\n",
    "    plt.plot(xs, ys, 'k.') # create the scatter plot\n",
    "    plt.xlabel('Min Freq')\n",
    "    plt.ylabel('Similarity')\n",
    "    print(\"Freq vs Similarity Spearman correlation = {:.2f}\".format(spearmanr(xs,ys)[0]))\n",
    "    #  plt.show() #display the set of plots\n",
    "\n",
    "def make_pairs(items):\n",
    "    '''Takes a list of items and creates a list of the unique pairs\n",
    "    with each pair sorted, so that if (a, b) is a pair, (b, a) is not\n",
    "    also included. Self-pairs (a, a) are also not included.\n",
    "\n",
    "    :type items: list\n",
    "    :param items: the list to pair up\n",
    "    :return: list of pairs\n",
    "\n",
    "    '''\n",
    "    return [(x, y) for x in items for y in items if x < y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to obtain HPCA vectors from word id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 200)\n",
      "(200,)\n",
      "[59.23344383 18.02161332 12.40352844 10.53883405  9.23316225  8.59590141\n",
      "  8.21714143  7.23592476  6.51846968  6.42240474  5.45478696  5.17993906\n",
      "  5.0902209   4.87143112  4.62890412  4.3660962   4.21239223  4.07724987\n",
      "  3.76047     3.57847436  3.48636012  3.43120839  3.38955165  3.09019564\n",
      "  3.00403568  2.97747017  2.93763361  2.87980145  2.79411418  2.70629938\n",
      "  2.61784133  2.59807637  2.54585305  2.46848535  2.40942928  2.39809242\n",
      "  2.31908218  2.29499994  2.28342287  2.15622733  2.12661859  2.08923084\n",
      "  2.07182863  2.05475217  2.0065745   1.96285993  1.9450299   1.92592624\n",
      "  1.87101424  1.84219514  1.81460442  1.80599726  1.7886071   1.72904761\n",
      "  1.70643462  1.69022358  1.67830548  1.65846842  1.61214321  1.59778202\n",
      "  1.59591548  1.57495838  1.56345064  1.54069811  1.53185726  1.52619551\n",
      "  1.51180912  1.49699631  1.48844418  1.47232016  1.46508851  1.44917173\n",
      "  1.42280127  1.41700712  1.40155454  1.39244696  1.38824712  1.3823981\n",
      "  1.36163994  1.35392525  1.35002807  1.34223185  1.33772147  1.32431974\n",
      "  1.31339234  1.30116291  1.29817287  1.28448846  1.27980657  1.26941637\n",
      "  1.25428075  1.24557621  1.23401335  1.22702023  1.22151565  1.21238417\n",
      "  1.20169354  1.19793786  1.19140475  1.180076    1.17331774  1.16473378\n",
      "  1.1606933   1.15684595  1.15216112  1.14594289  1.1351657   1.13117818\n",
      "  1.12683891  1.11263336  1.10852142  1.10187832  1.09809589  1.09196879\n",
      "  1.08888869  1.0845884   1.0803132   1.07305668  1.07055769  1.05888694\n",
      "  1.05555544  1.0472975   1.03851938  1.03189331  1.02996414  1.02395669\n",
      "  1.02229467  1.01769445  1.01149545  1.00691595  1.00311519  0.99924621\n",
      "  0.99580393  0.99388228  0.99205443  0.99133977  0.9820597   0.97546693\n",
      "  0.97440645  0.97074582  0.96697137  0.9605419   0.95988814  0.95649248\n",
      "  0.95291954  0.95129659  0.94251129  0.94056558  0.93342279  0.93116704\n",
      "  0.92461555  0.92164919  0.91565382  0.91300208  0.91006019  0.90688347\n",
      "  0.90309752  0.89864647  0.89569206  0.89195313  0.88965836  0.88631388\n",
      "  0.8849127   0.88345582  0.87642016  0.87322295  0.86975546  0.86765065\n",
      "  0.86176516  0.86096902  0.85751048  0.85610723  0.8517233   0.84926931\n",
      "  0.8453627   0.84058936  0.8391619   0.83594007  0.83524182  0.83054319\n",
      "  0.82735413  0.82180057  0.81725418  0.81625857  0.81523548  0.811084\n",
      "  0.80574391  0.80440548  0.80213199  0.79667441  0.79311931  0.79173315\n",
      "  0.78878802  0.78574864  0.78369809  0.78019294  0.77711721  0.7728736\n",
      "  0.77110619  0.76750037]\n"
     ]
    }
   ],
   "source": [
    "file_name = 'U_N=15000_K=200.npy'\n",
    "U = np.load(file_name)\n",
    "print(U.shape)\n",
    "\n",
    "file_name = 'S_N=15000_K=200.npy'\n",
    "S = np.load(file_name)\n",
    "print(S.shape)\n",
    "print(S)\n",
    "\n",
    "\n",
    "#sort the words in the twitter dataset by frequency\n",
    "o_counts = get_o_counts(\"/afs/inf.ed.ac.uk/group/teaching/anlp/lab8/counts\")\n",
    "sorted_o_counts = dict(sorted(o_counts.items(), key=operator.itemgetter(1),reverse=True))\n",
    "\n",
    "#find ranking of words\n",
    "positive_words_ranks = []\n",
    "for ID in positive_word_ids:\n",
    "    if ID in sorted_o_counts.keys():\n",
    "        positive_words_ranks.append(list(sorted_o_counts.keys()).index(ID))\n",
    "\n",
    "negative_words_ranks = []\n",
    "for ID in negative_word_ids:\n",
    "    if ID in sorted_o_counts.keys():\n",
    "        negative_words_ranks.append(list(sorted_o_counts.keys()).index(ID))\n",
    "        \n",
    "def wid2hpca_vec(wid):\n",
    "    if wid in sorted_o_counts.keys():\n",
    "        rank = list(sorted_o_counts.keys()).index(wid)\n",
    "    else:\n",
    "        print('Invalid ID: ', wid)\n",
    "        return None\n",
    "    \n",
    "    if rank < U.shape[0]: #checking that the word is in the U matrix\n",
    "        return U[rank,:] #return the embedding vector\n",
    "    else:\n",
    "        print('Rare word with ID: ', wid)\n",
    "        return None\n",
    "    \n",
    "def create_hpca_vectors(wids):\n",
    "    '''Creates embedding vectors for the words in wids, using HPCA.\n",
    "    These should be sparse vectors.\n",
    "\n",
    "    K (int) number of dimensions of the embedded vectors\n",
    "    '''\n",
    "    vectors = {}\n",
    "    for wid0 in wids:\n",
    "      vectors[wid0] = wid2hpca_vec(wid0)\n",
    "      \n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\t('cat', 'dog')                \t169733\t287114\n",
      "0.18\t('dog', 'hors')               \t287114\t57011\n",
      "0.15\t('polit', 'technolog')        \t77492\t71947\n",
      "0.14\t('histori', 'technolog')      \t128279\t71947\n",
      "0.13\t('cat', 'hors')               \t169733\t57011\n",
      "0.11\t('cat', 'histori')            \t169733\t128279\n",
      "0.00\t('dog', 'histori')            \t287114\t128279\n",
      "-0.03\t('histori', 'polit')          \t128279\t77492\n",
      "-0.05\t('hors', 'histori')           \t57011\t128279\n",
      "-0.06\t('cat', 'technolog')          \t169733\t71947\n",
      "-0.15\t('hors', 'polit')             \t57011\t77492\n",
      "-0.15\t('dog', 'polit')              \t287114\t77492\n",
      "-0.16\t('cat', 'polit')              \t169733\t77492\n",
      "-0.21\t('dog', 'technolog')          \t287114\t71947\n",
      "-0.22\t('hors', 'technolog')         \t57011\t71947\n"
     ]
    }
   ],
   "source": [
    "test_words = [\"cat\", \"dog\", \"horse\", \"technology\", \"politics\", \"history\"]\n",
    "stemmed_words = [tw_stemmer(w) for w in test_words]\n",
    "all_wids = set([word2wid[x] for x in stemmed_words])\n",
    "\n",
    "#print(word2wid.keys())\n",
    "# you could choose to just select some pairs and add them by hand instead\n",
    "# but here we automatically create all pairs \n",
    "wid_pairs = make_pairs(all_wids)\n",
    "\n",
    "\n",
    "#read in the HPCA vectors:\n",
    "vectors = create_hpca_vectors(all_wids)\n",
    "\n",
    "\n",
    "# compute cosine similarites for all pairs we consider\n",
    "c_sims = {(wid0,wid1): 1-weighted_cosine_dist(vectors[wid0],vectors[wid1],S) for (wid0,wid1) in wid_pairs}\n",
    "\n",
    "#print(\"Sort by cosine similarity\")\n",
    "print_sorted_pairs(c_sims, o_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\t('cat', 'dog')                \t169733\t287114\n",
      "0.07\t('polit', 'technolog')        \t77492\t71947\n",
      "0.07\t('dog', 'hors')               \t287114\t57011\n",
      "0.06\t('histori', 'polit')          \t128279\t77492\n",
      "0.06\t('histori', 'technolog')      \t128279\t71947\n",
      "0.02\t('cat', 'histori')            \t169733\t128279\n",
      "0.01\t('cat', 'hors')               \t169733\t57011\n",
      "-0.01\t('cat', 'technolog')          \t169733\t71947\n",
      "-0.01\t('hors', 'polit')             \t57011\t77492\n",
      "-0.04\t('dog', 'histori')            \t287114\t128279\n",
      "-0.05\t('hors', 'histori')           \t57011\t128279\n",
      "-0.06\t('cat', 'polit')              \t169733\t77492\n",
      "-0.10\t('dog', 'polit')              \t287114\t77492\n",
      "-0.12\t('dog', 'technolog')          \t287114\t71947\n",
      "-0.13\t('hors', 'technolog')         \t57011\t71947\n"
     ]
    }
   ],
   "source": [
    "test_words = [\"cat\", \"dog\", \"horse\", \"technology\", \"politics\", \"history\"]\n",
    "stemmed_words = [tw_stemmer(w) for w in test_words]\n",
    "all_wids = set([word2wid[x] for x in stemmed_words])\n",
    "\n",
    "#print(word2wid.keys())\n",
    "# you could choose to just select some pairs and add them by hand instead\n",
    "# but here we automatically create all pairs \n",
    "wid_pairs = make_pairs(all_wids)\n",
    "\n",
    "\n",
    "#read in the HPCA vectors:\n",
    "vectors = create_hpca_vectors(all_wids)\n",
    "\n",
    "def np_cosine_sim(vec1, vec2):\n",
    "    return np.dot(vec1, vec2)/(np.sum(vec1**2)*np.sum(vec2**2))**(0.5)\n",
    "\n",
    "# compute cosine similarites for all pairs we consider\n",
    "c_sims = {(wid0,wid1): np_cosine_sim(vectors[wid0],vectors[wid1]) for (wid0,wid1) in wid_pairs}\n",
    "\n",
    "#print(\"Sort by cosine similarity\")\n",
    "print_sorted_pairs(c_sims, o_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
